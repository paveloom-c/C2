{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring the rotation period of [KIC 1430163](https://archive.stsci.edu/kepler/data_search/search.php?target=1430163&action=Search&outputformat=HTML_Table) <br>from [Kepler](https://archive.stsci.edu/kepler/) using [<i>george</i>](https://github.com/dfm/george) for a custom kernel\n",
    "\n",
    "Based on the [revised version](https://github.com/Paveloom/C2/blob/master/Notebooks/Base/celerite/Revised/revised.ipynb) of the [example](https://github.com/dfm/celerite/blob/master/paper/figures/rotation/rotation.ipynb) from Foreman-Mackey ([2017](https://www.mendeley.com/catalogue/fast-scalable-gaussian-process-modeling-applications-astronomical-time-series/)). Written by [Pavel Sobolev](https://github.com/Paveloom) and located [here](https://github.com/Paveloom/C2). Release version: [0.2.1](https://github.com/Paveloom/C2/releases/tag/v0.2.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing standard modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:23:08.281276Z",
     "start_time": "2020-03-07T08:22:56.505Z"
    }
   },
   "outputs": [],
   "source": [
    "import re  # Regular expression operations\n",
    "import copy  # Deep copy operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing non-standard packages and modules:\n",
    "\n",
    "[kplr](https://github.com/dfm/kplr), [corner](https://github.com/dfm/corner.py), [emcee](https://github.com/dfm/emcee), and [george](https://github.com/dfm/george) developed by [Daniel Foreman-Mackey](https://github.com/dfm) and other contributors;<br>\n",
    "[matplotlib](https://github.com/matplotlib/matplotlib) developed by [Michael Droettboom](https://github.com/mdboom),  [Thomas Caswell](https://github.com/tacaswell) and other contributors;<br>\n",
    "[autograd](https://github.com/HIPS/autograd) developed by [Dougal Maclaurin](https://dougalmaclaurin.com), [David Duvenaud](https://www.cs.toronto.edu/~duvenaud/), [Matt Johnson](http://people.csail.mit.edu/mattjj/), [Jamie Townsend](https://github.com/j-towns) and other contributors;<br>\n",
    "[optimization](https://github.com/scipy/scipy/tree/master/scipy/optimize) module from [scipy](https://github.com/scipy/scipy) developed by contributors;<br>\n",
    "[timeseries](https://github.com/astropy/astropy/tree/master/astropy/timeseries) module from [astropy](https://github.com/astropy/astropy) developed by contributors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:23:08.282423Z",
     "start_time": "2020-03-07T08:22:56.508Z"
    }
   },
   "outputs": [],
   "source": [
    "import kplr  # Tools for working with Kepler data\n",
    "import corner  # Tools for making corner plots\n",
    "import emcee  # The Python ensemble sampling toolkit for affine-invariant MCMC\n",
    "\n",
    "from emcee import interruptible_pool as ip  # Interruptible Multiprocessing Pool\n",
    "from emcee import autocorr as ac  # Autocorrelation Function\n",
    "\n",
    "# Fast and flexible Gaussian Process regression in Python\n",
    "import george  # Full interface\n",
    "from george import kernels  # Kernels interfaces\n",
    "\n",
    "# Plots\n",
    "from matplotlib import rcParams as rcP  # Plot parameters\n",
    "from matplotlib import pyplot as plt  # 2D Plots\n",
    "from celerite import plot_setup  # Plot setup\n",
    "\n",
    "from autograd import numpy as np  # Derivatives of numpy code\n",
    "from scipy.optimize import minimize  # Minimization of a scalar function\n",
    "from astropy.timeseries import LombScargle  # Computing of the Lomb-Scargle Periodogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Setting plot parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:23:08.283300Z",
     "start_time": "2020-03-07T08:22:56.512Z"
    }
   },
   "outputs": [],
   "source": [
    "# A magic command to get inline plots within a Python Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# A magic command to enable 2x plots\n",
    "%config IPython.matplotlib.backend = \"retina\"\n",
    "\n",
    "# Setting the DPIs of figures\n",
    "rcP[\"savefig.dpi\"] = 300\n",
    "rcP[\"figure.dpi\"] = 300\n",
    "\n",
    "# Setting the Computer Modern Bright font\n",
    "rcP[\"text.usetex\"] = True\n",
    "rcP[\"text.latex.preamble\"] = r\"\\usepackage{cmbright}\"\n",
    "\n",
    "# Setting the font sizes\n",
    "rcP[\"font.size\"] = 16\n",
    "rcP[\"legend.fontsize\"] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading sample data from the [Kepler Input Catalog](https://archive.stsci.edu/kepler/kic.html) (field descriptors are taken from [Kepler Archive Manual](https://archive.stsci.edu/files/live/sites/mast/files/home/missions-and-data/kepler/_documents/archive_manual.pdf)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:23:08.284140Z",
     "start_time": "2020-03-07T08:22:56.515Z"
    }
   },
   "outputs": [],
   "source": [
    "# The ID of a star from the Kepler Input Catalog\n",
    "KIC_ID = 1430163\n",
    "\n",
    "# Attaching the kplr API\n",
    "client = kplr.API()\n",
    "\n",
    "# Getting the star data\n",
    "star = client.star(KIC_ID)\n",
    "\n",
    "# Time values\n",
    "t = []\n",
    "\n",
    "# Pre-search Data Conditioning Simple Aperture Photometry (PDCSAP) flux values\n",
    "f = []\n",
    "\n",
    "# The 1-sigma errors in PDC flux values\n",
    "ferr = []\n",
    "\n",
    "# Getting long cadence data of light curves\n",
    "for lc in star.get_light_curves(short_cadence=False):\n",
    "\n",
    "    # Reading data from a light curve\n",
    "    data = lc.read()\n",
    "\n",
    "    # Getting time values from the data\n",
    "    t0 = data[\"TIME\"]\n",
    "\n",
    "    # Getting PDCSAP flux values from the data\n",
    "    f0 = data[\"PDCSAP_FLUX\"]\n",
    "\n",
    "    # Creating a mask for only qualitative data points\n",
    "    mask = (data[\"SAP_QUALITY\"] == 0) & np.isfinite(t0) & np.isfinite(f0)\n",
    "\n",
    "    # Appending the qualitative time data to the existing list\n",
    "    t.append(t0[mask])\n",
    "\n",
    "    # Computing the median of the flux data\n",
    "    mu = np.median(f0[mask])\n",
    "\n",
    "    # Scaling the qualitative flux data and appending these to the existing list\n",
    "    f.append((f0[mask] / mu - 1.0) * 1e3)\n",
    "\n",
    "    # Scaling the qualitative flux errors data and appending these to the existing list\n",
    "    ferr.append(data[\"PDCSAP_FLUX_ERR\"][mask] / mu * 1e3)\n",
    "\n",
    "# Concatenating the arrays within the lists\n",
    "\n",
    "t = np.concatenate(t)\n",
    "f = np.concatenate(f)\n",
    "ferr = np.concatenate(ferr)\n",
    "\n",
    "# Getting contiguous arrays\n",
    "\n",
    "t = np.ascontiguousarray(t, dtype=float)\n",
    "f = np.ascontiguousarray(f, dtype=float)\n",
    "ferr = np.ascontiguousarray(ferr, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Making a first guess at the period using the Lomb-Scargle periodogram (see, e.g VanderPlas ([2017](https://www.mendeley.com/catalogue/understanding-lombscargle-periodogram-1/))) <br>and comparing it to the real value known from Mathur et al. ([2014](https://www.mendeley.com/catalogue/investigating-magnetic-activity-f-stars-kepler-mission/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:23:08.285129Z",
     "start_time": "2020-03-07T08:22:56.518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a set of evenly spaced frequencies\n",
    "freq = np.linspace(1e-1, 1.0, 5000)\n",
    "\n",
    "# Getting the PSD-normalized Lomb-Scargle power spectrum of the data using the fast method (O[N log N])\n",
    "power = LombScargle(t, f).power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "# Determining the maximum peak\n",
    "period = 1.0 / freq[np.argmax(power)]\n",
    "\n",
    "# Printing the x value of this peak\n",
    "print(\"The maximum peak is at \" + str(period))\n",
    "\n",
    "# Scaling the output\n",
    "power /= len(t)\n",
    "\n",
    "# Plotting the result with emphasis on the period value\n",
    "# and comparing it to the real value\n",
    "\n",
    "# Plotting data\n",
    "plt.plot(1.0 / freq, power, color=\"#425378\")\n",
    "\n",
    "# Marking the true period value\n",
    "plt.axvline(3.88, color=\"#7C40A0\", alpha=0.5)\n",
    "\n",
    "# Adding approximate period values on the plot\n",
    "plt.text(3.9, 0.0006, r\"$\\approx$ 3.88 days\", fontsize=12)\n",
    "plt.text(4.385, 0.0006, r\"$\\approx$ 4.358 days\", fontsize=12)\n",
    "\n",
    "# Setting limits\n",
    "plt.xlim(period - 1, period + 1)\n",
    "plt.ylim(0, 0.0007)\n",
    "\n",
    "# Setting labels\n",
    "plt.xlabel(\"Period, days\")\n",
    "plt.ylabel(\"Power\")\n",
    "\n",
    "# Setting title\n",
    "plt.title(\"Lomb-Scargle periodogram\")\n",
    "\n",
    "# Saving the figure\n",
    "plt.savefig(\"Figures/LS_periodogram\", bbox_inches=\"tight\")\n",
    "\n",
    "# Showing the result\n",
    "plt.show()\n",
    "\n",
    "# Closing the plot\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Taking a subset of the data (here: quarters [4](https://archive.stsci.edu/kepler/preview.php?type=lc&dsn=KPLR001430163-2010078095331) and [5](https://archive.stsci.edu/kepler/preview.php?type=lc&dsn=KPLR001430163-2010174085026) of the long cadence data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:23:08.286392Z",
     "start_time": "2020-03-07T08:22:56.522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining a mask with time bounds\n",
    "mask = (t >= 352.396596505) & (t <= 537.5502295)\n",
    "\n",
    "# Taking the subset\n",
    "t = t[mask]\n",
    "f = f[mask]\n",
    "ferr = ferr[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Defining the covariance function as described in the example from Foreman-Mackey ([2017](https://www.mendeley.com/catalogue/fast-scalable-gaussian-process-modeling-applications-astronomical-time-series/)):\n",
    "\n",
    "replicating the properties of\n",
    "\n",
    "$ \\LARGE k(\\tau) = A \\exp\\left( - \\frac{\\tau^2}{2 l^2} - \\Gamma \\sin^2\\left( \\frac{\\pi \\tau}{P_{rot}} \\right) \\right)$\n",
    "\n",
    "by constructing a simple <i>celerite</i> covariance function\n",
    "\n",
    "$ \\LARGE k(\\tau) = \\frac{a}{2 \\ + \\ b} e^{-\\tau/c} \\left[ \\cos\\left( \\frac{2 \\pi \\tau}{P} \\right) + (1 + b) \\right] $\n",
    "\n",
    "The parameters are defined by logarithms in the code for the simplicity of specifying priors.\n",
    "\n",
    "[Custom kernel](https://github.com/Paveloom/C2/tree/master/Notebooks/Base/celerite/Kernel/RotationKernel.yml) is compiled locally since george [doesn't support](https://george.readthedocs.io/en/latest/tutorials/new-kernel/#new-kernel) in-place defining because of technical limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:23:08.287506Z",
     "start_time": "2020-03-07T08:22:56.526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the priors\n",
    "bounds = dict(log_amp=(-10.0, 0.0), log_timescale=(1.5, 5.0),\n",
    "              log_period=(-3.0, 5.0), log_factor=(-5.0, 5.0))\n",
    "\n",
    "# Building a kernel\n",
    "kernel = kernels.RotationKernel(\n",
    "    log_amp=np.log(np.var(f)),\n",
    "    log_timescale=np.log(10.0),\n",
    "    log_period=np.log(period),\n",
    "    log_factor=np.log(1.0),\n",
    "    bounds=bounds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creating a Gaussian process model with the specified kernel; defining the functions \n",
    "for computing negative marginalized log likelihood and the gradient of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:23:08.288900Z",
     "start_time": "2020-03-07T08:22:56.530Z"
    }
   },
   "outputs": [],
   "source": [
    "# Building a celerite model with the specified kernel\n",
    "gp = george.GP(kernel, mean=np.median(f))\n",
    "\n",
    "# Computing the extended form of the covariance matrix and factorizing\n",
    "gp.compute(t, ferr)\n",
    "\n",
    "\n",
    "def neg_log_like(params, y, model, m):\n",
    "    \"\"\"\n",
    "    \n",
    "    A function to get the negative marginalized log likelihood\n",
    "\n",
    "    Parameters:\n",
    "        params: An array containing parameter values;\n",
    "        y : An array of data;\n",
    "        model : A GP model;\n",
    "        m : A mask for an array of data\n",
    "\n",
    "    Returns:\n",
    "        The negative marginalized log likelihood\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Setting parameter values to the given vector\n",
    "    model.set_parameter_vector(params)\n",
    "\n",
    "    # Computing and returning the result\n",
    "    return -model.log_likelihood(y[m])\n",
    "\n",
    "\n",
    "def grad_neg_log_like(params, y, model, m):\n",
    "    \"\"\"\n",
    "    \n",
    "    A function to get the gradient of\n",
    "    the negative marginalized likelihood \n",
    "\n",
    "    Parameters:\n",
    "        params: An array containing parameter values;\n",
    "        y : An array of data;\n",
    "        model : A GP model;\n",
    "        m : A mask for an array of data\n",
    "\n",
    "    Returns:\n",
    "        The gradient of the negative\n",
    "        marginalized likelihood\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Setting parameter values to the given vector\n",
    "    model.set_parameter_vector(params)\n",
    "\n",
    "    # Computing and returning the result\n",
    "    return -model.grad_log_likelihood(y[m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-by-step $\\Large\\sigma$-clipping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:23:08.289829Z",
     "start_time": "2020-03-07T08:22:56.533Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting the values of the initial parameters\n",
    "init_params = gp.get_parameter_vector()\n",
    "\n",
    "# Getting the names of the parameters\n",
    "params_names = [re.sub(r\".*:\", \"\", name) for name in gp.get_parameter_names()]\n",
    "\n",
    "# Getting bounds values\n",
    "bounds_values = gp.get_parameter_bounds()\n",
    "\n",
    "# Creating an initial mask\n",
    "sigma_mask = np.ones(len(t), dtype=bool)\n",
    "\n",
    "gp.compute(t[sigma_mask], ferr[sigma_mask])\n",
    "print(grad_neg_log_like(init_params, f, gp, sigma_mask))\n",
    "\n",
    "# Main loop\n",
    "while False:\n",
    "\n",
    "    # Computing the extended form of the covariance matrix and factorizing\n",
    "    gp.compute(t[sigma_mask], ferr[sigma_mask])\n",
    "\n",
    "    # Minimizing the negative marginalized likelihood using the L-BFGS-B method\n",
    "    opt = minimize(neg_log_like, init_params, jac=grad_neg_log_like,\n",
    "                   method=\"L-BFGS-B\", bounds=bounds_values, args=(f, gp, sigma_mask))\n",
    "\n",
    "    # Setting the new parameters\n",
    "    gp.set_parameter_vector(opt.x)\n",
    "\n",
    "    # Computing the conditional predictive distribution of the model\n",
    "    mu, var = gp.predict(f[sigma_mask], t, return_var=True)\n",
    "\n",
    "    # Calculating standard deviation\n",
    "    sig = np.sqrt(var + ferr ** 2)\n",
    "\n",
    "    # Calculating the residuals\n",
    "    rds = f - mu\n",
    "\n",
    "    # Calculating a new mask\n",
    "    new_sigma_mask = np.abs(rds) < 3 * sig\n",
    "\n",
    "    # Comparing the masks\n",
    "    if np.all(new_sigma_mask == sigma_mask):\n",
    "        break\n",
    "\n",
    "    # Updating the mask\n",
    "    sigma_mask[:] = new_sigma_mask\n",
    "\n",
    "# Saving the arrays using the computed mask\n",
    "fit_t, fit_f, fit_ferr = t[sigma_mask], f[sigma_mask], ferr[sigma_mask]\n",
    "\n",
    "# Copying ``gp``\n",
    "ml_gp = copy.deepcopy(gp)\n",
    "\n",
    "# Computing the extended form of the covariance matrix and factorizing\n",
    "ml_gp.compute(fit_t, fit_ferr)\n",
    "\n",
    "# Computing the marginalized log likelihood\n",
    "ml_gp.log_likelihood(fit_f)\n",
    "\n",
    "# Printing the optimal parameters\n",
    "\n",
    "print(\"The maximum a posteriori parameters (MAP) inferred by\\n\",\n",
    "      \"minimizing the negative marginalized likelihood: \\n\", sep=\"\")\n",
    "\n",
    "for i in range(len(params_names)):\n",
    "    print(params_names[i] + \":\", opt.x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:23:08.290768Z",
     "start_time": "2020-03-07T08:22:56.536Z"
    }
   },
   "outputs": [],
   "source": [
    "[-2395.6919298   2386.93237776   632.25350827    71.56259315]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
